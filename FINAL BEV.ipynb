{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def blend_images(base, overlay):\n",
    "    gray = cv2.cvtColor(overlay, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    bg = cv2.bitwise_and(base, base, mask=mask_inv)\n",
    "    fg = cv2.bitwise_and(overlay, overlay, mask=mask)\n",
    "    return cv2.add(bg, fg)\n",
    "\n",
    "def compute_homography(sift, matcher, img1, img2):\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    matches = matcher.knnMatch(des2, des1, k=2)\n",
    "    good = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "    if len(good) > 10:\n",
    "        src_pts = np.float32([kp2[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp1[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "        H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        return H\n",
    "    else:\n",
    "        raise ValueError(\"Not enough matches for homography.\")\n",
    "\n",
    "def detect_lanes_and_overlay(image): \n",
    "    if image is None:\n",
    "        return image\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "    output = image.copy()\n",
    "\n",
    "    x_offset = 223\n",
    "    cropped = image[:, x_offset:-x_offset]\n",
    "    cropped_width = cropped.shape[1]\n",
    "\n",
    "    region_height = 250\n",
    "    cropped_height = cropped.shape[0]\n",
    "    regions = {\n",
    "        \"Top\": (0, region_height)\n",
    "    }\n",
    "#     regions = {\n",
    "#         \"Top\": (0, region_height),\n",
    "#         \"Bottom\": (cropped_height - region_height, cropped_height)\n",
    "#     }\n",
    "\n",
    "    for y_start, y_end in regions.values():\n",
    "        region = cropped[y_start:y_end, :]\n",
    "        gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=50, maxLineGap=20)\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                x1_full = x1 + x_offset\n",
    "                x2_full = x2 + x_offset\n",
    "                y1_full = y1 + y_start\n",
    "                y2_full = y2 + y_start\n",
    "                cv2.line(output, (x1_full, y1_full), (x2_full, y2_full), (0, 255, 0), 2)\n",
    "\n",
    "    return output\n",
    "\n",
    "# --- Setup ---\n",
    "dataset_dir = r\"C:\\Users\\ASUS\\Labs\\IVP\\Dataset\"\n",
    "sample_data_file = os.path.join(dataset_dir, \"v1.0-mini\", \"sample_data.json\")\n",
    "sample_data = load_json(sample_data_file)\n",
    "\n",
    "front_keys = {\n",
    "    \"front\": \"sweeps/CAM_FRONT/\",\n",
    "    \"front_left\": \"sweeps/CAM_FRONT_LEFT/\",\n",
    "    \"front_right\": \"sweeps/CAM_FRONT_RIGHT/\"\n",
    "}\n",
    "back_keys = {\n",
    "    \"back\": \"sweeps/CAM_BACK/\",\n",
    "    \"back_left\": \"sweeps/CAM_BACK_RIGHT/\",\n",
    "    \"back_right\": \"sweeps/CAM_BACK_LEFT\"\n",
    "}\n",
    "\n",
    "def group_and_sort_frames(keys):\n",
    "    grouped = {key: [] for key in keys}\n",
    "    for sample in sample_data:\n",
    "        for key, path in keys.items():\n",
    "            if path in sample[\"filename\"]:\n",
    "                grouped[key].append(sample)\n",
    "    for key in grouped:\n",
    "        grouped[key] = sorted(grouped[key], key=lambda x: x[\"timestamp\"])\n",
    "    return grouped\n",
    "\n",
    "front_frames = group_and_sort_frames(front_keys)\n",
    "back_frames = group_and_sort_frames(back_keys)\n",
    "\n",
    "ref_paths = {\n",
    "    \"back\": os.path.join(dataset_dir, r\"sweeps\\CAM_BACK\\n008-2018-08-01-15-16-36-0400__CAM_BACK__1533151609637558.jpg\"),\n",
    "    \"back_left\": os.path.join(dataset_dir, r\"sweeps\\CAM_BACK_RIGHT\\n008-2018-08-01-15-16-36-0400__CAM_BACK_RIGHT__1533151609378113.jpg\"),\n",
    "    \"back_right\": os.path.join(dataset_dir, r\"sweeps\\CAM_BACK_LEFT\\n008-2018-08-01-15-16-36-0400__CAM_BACK_LEFT__1533151609447405.jpg\")\n",
    "}\n",
    "ref_paths.update({\n",
    "    \"front\": os.path.join(dataset_dir, front_frames[\"front\"][0][\"filename\"].replace(\"/\", \"\\\\\")),\n",
    "    \"front_left\": os.path.join(dataset_dir, front_frames[\"front_left\"][0][\"filename\"].replace(\"/\", \"\\\\\")),\n",
    "    \"front_right\": os.path.join(dataset_dir, front_frames[\"front_right\"][0][\"filename\"].replace(\"/\", \"\\\\\"))\n",
    "})\n",
    "\n",
    "ref_images = {k: cv2.imread(p) for k, p in ref_paths.items()}\n",
    "if any(img is None for img in ref_images.values()):\n",
    "    raise ValueError(\"Failed to load one or more reference images.\")\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "matcher = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5), dict(checks=50))\n",
    "\n",
    "H_front_left = compute_homography(sift, matcher, ref_images[\"front\"], ref_images[\"front_left\"])\n",
    "H_front_right = compute_homography(sift, matcher, ref_images[\"front\"], ref_images[\"front_right\"])\n",
    "H_back_left = compute_homography(sift, matcher, ref_images[\"back\"], ref_images[\"back_left\"])\n",
    "H_back_right = compute_homography(sift, matcher, ref_images[\"back\"], ref_images[\"back_right\"])\n",
    "\n",
    "h, w = ref_images[\"front\"].shape[:2]\n",
    "canvas_h, canvas_w = h * 2, w * 5\n",
    "offset_x, offset_y = w * 2, h // 2\n",
    "T = np.array([[1, 0, offset_x], [0, 1, offset_y], [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "H_front_left_warp = (T @ H_front_left).astype(np.float32)\n",
    "H_front_right_warp = (T @ H_front_right).astype(np.float32)\n",
    "H_back_left_warp = (T @ H_back_left).astype(np.float32)\n",
    "H_back_right_warp = (T @ H_back_right).astype(np.float32)\n",
    "\n",
    "source_points =  np.float32([\n",
    "    [3000, 1200], [5000, 1200],\n",
    "    [1500, 1600], [6500, 1600]\n",
    "])\n",
    "destination_points = np.float32([\n",
    "    [300, 0], [700, 0],\n",
    "    [300, 800], [700, 800]\n",
    "])\n",
    "bev_H = cv2.getPerspectiveTransform(source_points, destination_points)\n",
    "\n",
    "ego_car_path = r\"C:\\Users\\ASUS\\Downloads\\download-removebg-preview.png\"\n",
    "ego_car = cv2.imread(ego_car_path, cv2.IMREAD_UNCHANGED)\n",
    "if ego_car is None:\n",
    "    raise ValueError(\"Ego car image not found!\")\n",
    "\n",
    "cv2.namedWindow(\"Combined BEV\", cv2.WINDOW_AUTOSIZE)\n",
    "num_frames = min(len(front_frames[\"front\"]), len(front_frames[\"front_left\"]), len(front_frames[\"front_right\"]),\n",
    "                 len(back_frames[\"back\"]), len(back_frames[\"back_left\"]), len(back_frames[\"back_right\"]))\n",
    "\n",
    "for i in range(num_frames):\n",
    "    def load_cam_images(keys, frames):\n",
    "        return {\n",
    "            key: cv2.imread(os.path.join(dataset_dir, frames[key][i][\"filename\"].replace(\"/\", \"\\\\\")))\n",
    "            for key in keys\n",
    "        }\n",
    "\n",
    "    front_imgs = load_cam_images(front_keys, front_frames)\n",
    "    back_imgs = load_cam_images(back_keys, back_frames)\n",
    "\n",
    "    if any(img is None for img in list(front_imgs.values()) + list(back_imgs.values())):\n",
    "        continue\n",
    "\n",
    "    f_base = cv2.warpPerspective(front_imgs[\"front\"], T, (canvas_w, canvas_h))\n",
    "    f_left = cv2.warpPerspective(front_imgs[\"front_left\"], H_front_left_warp, (canvas_w, canvas_h))\n",
    "    f_right = cv2.warpPerspective(front_imgs[\"front_right\"], H_front_right_warp, (canvas_w, canvas_h))\n",
    "    f_canvas = blend_images(f_base, f_left)\n",
    "    f_canvas = blend_images(f_canvas, f_right)\n",
    "    f_bev = cv2.warpPerspective(f_canvas, bev_H, (1000, 800))\n",
    "\n",
    "    b_base = cv2.warpPerspective(back_imgs[\"back\"], T, (canvas_w, canvas_h))\n",
    "    b_left = cv2.warpPerspective(back_imgs[\"back_left\"], H_back_left_warp, (canvas_w, canvas_h))\n",
    "    b_right = cv2.warpPerspective(back_imgs[\"back_right\"], H_back_right_warp, (canvas_w, canvas_h))\n",
    "    b_canvas = blend_images(b_base, b_left)\n",
    "    b_canvas = blend_images(b_canvas, b_right)\n",
    "    b_bev = cv2.warpPerspective(b_canvas, bev_H, (1000, 800))\n",
    "\n",
    "    b_bev_flipped = cv2.flip(cv2.flip(b_bev, 0), 1)\n",
    "    combined_bev = np.vstack([f_bev, b_bev_flipped])\n",
    "\n",
    "    car_target_height = 900\n",
    "    car_target_width = int(car_target_height * ego_car.shape[1] / ego_car.shape[0]) - 250\n",
    "    ego_car_resized = cv2.resize(ego_car, (car_target_width, car_target_height))\n",
    "\n",
    "    x_offset = (combined_bev.shape[1] - car_target_width) // 2\n",
    "    y_offset = (combined_bev.shape[0] - car_target_height) // 2\n",
    "\n",
    "    alpha = ego_car_resized[:, :, 3] / 255.0\n",
    "    for c in range(3):\n",
    "        combined_bev[y_offset:y_offset+car_target_height, x_offset:x_offset+car_target_width, c] = (\n",
    "            (1 - alpha) * combined_bev[y_offset:y_offset+car_target_height, x_offset:x_offset+car_target_width, c] +\n",
    "            alpha * ego_car_resized[:, :, c]\n",
    "        ).astype(np.uint8)\n",
    "\n",
    "    combined_bev = cv2.resize(combined_bev, (1000, 1000))\n",
    "    combined_bev = combined_bev[:, 190:-190]\n",
    "\n",
    "    # --- Detect and Draw Lanes ---\n",
    "    combined_bev = detect_lanes_and_overlay(combined_bev)\n",
    "\n",
    "    cv2.imshow(\"Combined BEV\", combined_bev)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
